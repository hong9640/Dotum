"""
ë°°ì¹˜ í”¼ë“œë°± ìƒì„± ì„œë¹„ìŠ¤ (ë¦¬íŒ©í† ë§ ë²„ì „)

ê°„ê²°í•˜ê³  ëª…í™•í•œ ë¡œì§ìœ¼ë¡œ ì¬ì‘ì„±
"""
from typing import Optional, List, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlmodel import select
import json

from api.src.train.repositories.feedback import FeedbackRepository
from api.core.openai_provider import openai_provider
from api.src.train.models.training_item import TrainingItem
from api.src.train.models.praat import PraatFeatures
from api.src.train.models.media import MediaFile, MediaType
from api.src.train.models.words import TrainWords
from api.src.train.models.sentences import TrainSentences
from api.core.logging import get_logger

logger = get_logger(__name__)


class BatchFeedbackService:
    """ë°°ì¹˜ í”¼ë“œë°± ìƒì„± ì„œë¹„ìŠ¤"""
    
    MODEL_VERSION = "gpt-5-mini"  # LLM ëª¨ë¸ ë²„ì „
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self.repository = FeedbackRepository(db)
        self.provider = openai_provider
    
    async def generate_and_save_session_feedback(
        self,
        session_id: int,
        user_name: str
    ) -> bool:
        """
        ì„¸ì…˜ í‰ê·  í”¼ë“œë°± + ëª¨ë“  ì•„ì´í…œ í”¼ë“œë°± ë°°ì¹˜ ìƒì„±
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"[Batch] Starting feedback generation for session {session_id}")
            
            # 1. SessionPraatResult ì¡°íšŒ
            praat_result = await self.repository.get_session_praat_result_by_session_id(session_id)
            if not praat_result:
                logger.warning(f"[Batch] No SessionPraatResult for session {session_id}")
                return False
            
            # 2. ì¤‘ë³µ ì²´í¬
            existing_feedback = await self.repository.get_session_feedback_by_praat_result_id(
                praat_result.id
            )
            if existing_feedback:
                logger.info(f"[Batch] Feedback already exists for session {session_id}")
                return True
            
            # 3. ì•„ì´í…œ ë°ì´í„° ì¡°íšŒ
            items_data = await self._get_items_with_praat(session_id)
            
            if not items_data:
                # ì•„ì´í…œ ì—†ìœ¼ë©´ ì„¸ì…˜ í”¼ë“œë°±ë§Œ ìƒì„±
                logger.info(f"[Batch] No items, generating session feedback only")
                await self._save_session_feedback_only(praat_result, user_name)
                return True
            
            # 4. ë°°ì¹˜ LLM í˜¸ì¶œ
            batch_result = await self._generate_batch_feedback(
                praat_result, items_data, user_name
            )
            
            # 5. ì„¸ì…˜ í”¼ë“œë°± ì €ì¥
            await self.repository.create_session_feedback(
                session_praat_result_id=praat_result.id,
                feedback_text=batch_result["session_feedback"],
                model_version=batch_result["model_version"]
            )
            logger.info(f"[Batch] Session feedback saved")
            
            # 6. ì•„ì´í…œ í”¼ë“œë°± ì €ì¥
            await self._save_item_feedbacks(
                batch_result.get("items", []),
                items_data
            )
            
            logger.info(f"[Batch] âœ… All feedbacks saved for session {session_id}")
            return True
            
        except Exception as e:
            logger.error(f"[Batch] âŒ Failed: {e}", exc_info=True)
            await self.db.rollback()
            return False
    
    async def _get_items_with_praat(
        self,
        session_id: int
    ) -> List[Dict[str, Any]]:
        """
        ì•„ì´í…œ + Praat ë°ì´í„° ì¡°íšŒ (ìµœì í™”)
        
        Returns:
            [
                {
                    "item_index": 0,
                    "praat_features_id": 123,
                    "expected_text": "ì‚¬ê³¼",
                    "praat": {...}
                },
                ...
            ]
        """
        logger.debug(f"[Batch] Fetching items with praat for session {session_id}")
        
        # 1. ì™„ë£Œëœ ì•„ì´í…œ ì¡°íšŒ (VIDEO MediaFile í¬í•¨)
        items_stmt = (
            select(TrainingItem, MediaFile)
            .join(MediaFile, TrainingItem.media_file_id == MediaFile.id)
            .where(TrainingItem.training_session_id == session_id)
            .where(TrainingItem.is_completed == True)
            .where(MediaFile.media_type == MediaType.VIDEO)
            .order_by(TrainingItem.item_index)
        )
        items_result = await self.db.execute(items_stmt)
        items_with_video = items_result.all()
        
        if not items_with_video:
            logger.debug(f"[Batch] No completed items found")
            return []
        
        logger.debug(f"[Batch] Found {len(items_with_video)} completed items")
        
        # 2. VIDEO -> AUDIO object_key ë³€í™˜
        audio_keys = [
            video_media.object_key.replace('.mp4', '.wav').replace('.MP4', '.wav')
            for _, video_media in items_with_video
        ]
        logger.debug(f"[Batch] Looking for {len(audio_keys)} audio files")
        
        # 3. AUDIO MediaFile + PraatFeatures ì¡°íšŒ (JOINìœ¼ë¡œ í•œ ë²ˆì—)
        audio_praat_stmt = (
            select(MediaFile, PraatFeatures)
            .join(PraatFeatures, MediaFile.id == PraatFeatures.media_id)
            .where(MediaFile.object_key.in_(audio_keys))
            .where(MediaFile.media_type == MediaType.AUDIO)
        )
        audio_praat_result = await self.db.execute(audio_praat_stmt)
        audio_praat_list = audio_praat_result.all()
        
        if not audio_praat_list:
            logger.warning(f"[Batch] No audio/praat data found")
            return []
        
        logger.debug(f"[Batch] Found {len(audio_praat_list)} audio+praat pairs")
        
        # 4. word/sentence ì¼ê´„ ì¡°íšŒ (N+1 ë¬¸ì œ í•´ê²°)
        word_ids = [item.word_id for item, _ in items_with_video if item.word_id]
        sentence_ids = [item.sentence_id for item, _ in items_with_video if item.sentence_id]
        
        words_map = {}
        sentences_map = {}
        
        if word_ids:
            words_stmt = select(TrainWords).where(TrainWords.id.in_(word_ids))
            words_result = await self.db.execute(words_stmt)
            words_list = words_result.scalars().all()
            words_map = {w.id: w.word for w in words_list}
            logger.debug(f"[Batch] Loaded {len(words_map)} words")
        
        if sentence_ids:
            sentences_stmt = select(TrainSentences).where(TrainSentences.id.in_(sentence_ids))
            sentences_result = await self.db.execute(sentences_stmt)
            sentences_list = sentences_result.scalars().all()
            sentences_map = {s.id: s.sentence for s in sentences_list}
            logger.debug(f"[Batch] Loaded {len(sentences_map)} sentences")
        
        # 5. AUDIO object_key -> (Item, PraatFeatures) ë§¤í•‘
        audio_key_to_praat = {audio.object_key: praat for audio, praat in audio_praat_list}
        
        # 6. ë°ì´í„° ì¡°í•©
        items_data = []
        for item, video_media in items_with_video:
            # VIDEO -> AUDIO object_key
            audio_key = video_media.object_key.replace('.mp4', '.wav').replace('.MP4', '.wav')
            
            # PraatFeatures ì°¾ê¸°
            praat = audio_key_to_praat.get(audio_key)
            if not praat:
                logger.warning(f"[Batch] No praat for item {item.item_index}")
                continue
            
            # í…ìŠ¤íŠ¸ ì¡°íšŒ (ë¯¸ë¦¬ ë¡œë“œëœ ë§µì—ì„œ)
            expected_text = None
            if item.word_id:
                expected_text = words_map.get(item.word_id)
            elif item.sentence_id:
                expected_text = sentences_map.get(item.sentence_id)
            
            items_data.append({
                "item_index": item.item_index,
                "praat_features_id": praat.id,
                "expected_text": expected_text or f"item_{item.item_index}",
                "praat": {
                    "f0": praat.f0,
                    "f1": praat.f1,
                    "f2": praat.f2,
                    "hnr": praat.hnr,
                    "cpp": praat.cpp,
                    "csid": praat.csid,
                    "jitter_local": praat.jitter_local,
                    "shimmer_local": praat.shimmer_local,
                    "intensity_mean": praat.intensity_mean
                }
            })
        
        # item_index ìˆœì„œë¡œ ì •ë ¬
        items_data.sort(key=lambda x: x["item_index"])
        
        logger.info(f"[Batch] âœ… Prepared {len(items_data)} items for LLM")
        return items_data
    
    async def _generate_batch_feedback(
        self,
        praat_result: Any,
        items_data: List[Dict],
        user_name: str
    ) -> Dict[str, Any]:
        """
        ë°°ì¹˜ LLM í˜¸ì¶œ
        
        Returns:
            {
                "session_feedback": "...",
                "items": [...],
                "model_version": "..."
            }
        """
        # ì„¸ì…˜ í‰ê·  ì§€í‘œ
        session_avg = {
            "hnr": praat_result.avg_hnr,
            "cpp": praat_result.avg_cpp,
            "csid": praat_result.avg_csid,
            "f0": praat_result.avg_f0,
            "f1": praat_result.avg_f1,
            "f2": praat_result.avg_f2,
            "jitter": praat_result.avg_jitter_local,
            "shimmer": praat_result.avg_shimmer_local,
            "intensity": praat_result.avg_intensity_mean
        }
        
        # ì•„ì´í…œ ìš”ì•½
        items_summary = [
            {
                "index": item["item_index"],
                "text": item["expected_text"],
                "hnr": round(item["praat"]["hnr"], 1) if item["praat"]["hnr"] else None,
                "cpp": round(item["praat"]["cpp"], 2) if item["praat"]["cpp"] else None,
                "csid": round(item["praat"]["csid"], 1) if item["praat"]["csid"] else None,
                "f1": round(item["praat"]["f1"], 0) if item["praat"]["f1"] else None,
                "f2": round(item["praat"]["f2"], 0) if item["praat"]["f2"] else None
            }
            for item in items_data
        ]
        
        # ì—°ìŠµí•œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        practiced_words = [item["text"] for item in items_summary]
        words_str = ", ".join([f"'{w}'" for w in practiced_words[:10]])  # ìµœëŒ€ 10ê°œ
        
        # Few-shot ì˜ˆì‹œ
        few_shot_examples = """
**ì˜ˆì‹œ 1 - ì¢‹ì€ ì„¸ì…˜:**
ì…ë ¥: hnr=18.2, cpp=13.5, csid=15.8, items=["ì‚¬ê³¼", "ë‚˜ë¬´", "ë°”ëŒ"]
ì¶œë ¥:
{
  "session_feedback": "ì˜¤ëŠ˜ ì •ë§ ìˆ˜ê³  ë§ìœ¼ì…¨ì–´ìš”. ëª©ì†Œë¦¬ë¥¼ í•˜ë‚˜í•˜ë‚˜ ì‚´í´ë³´ë©´ì„œ ë”°ëœ»í•œ ìˆœê°„ë“¤ì´ ëŠê»´ì¡Œì–´ìš”.\\n\\nğŸŒŸ ì •ë§ ì˜í•˜ê³  ê³„ì‹  ë¶€ë¶„\\n\\n1) ë°œìŒì´ ì •ë§ ë˜ë ·í•´ìš”. 'ì‚¬ê³¼', 'ë‚˜ë¬´', 'ë°”ëŒ' ëª¨ë‘ì—ì„œ ëì†Œë¦¬ê¹Œì§€ ë¶„ëª…í•˜ê²Œ ë“¤ë ¤ì„œ ì¢‹ì•˜ì–´ìš”.\\n\\n2) ì†Œë¦¬ê°€ ì•ˆì •ì ìœ¼ë¡œ ì´ì–´ì¡Œì–´ìš”. ë§í•˜ëŠ” ì¤‘ê°„ì— ííŠ¸ëŸ¬ì§€ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ¬ì› ì–´ìš”.\\n\\n3) ëª©ì— í˜ì´ ê±°ì˜ ëŠê»´ì§€ì§€ ì•Šì•˜ì–´ìš”. í¸ì•ˆí•˜ê²Œ ë°œì„±í•˜ë ¤ëŠ” ë…¸ë ¥ì´ ë³´ì˜€ì–´ìš”.\\n\\n4) í˜¸í¡ì´ ì•ˆì •ì ì´ì—ˆì–´ìš”. ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šê³  ë§¤ë„ëŸ½ê²Œ ì™„ì„±ë˜ì—ˆì–´ìš”.\\n\\nğŸ’­ ì¡°ê¸ˆë§Œ ë” ì‹ ê²½ ì“°ë©´ ì¢‹ì„ ë¶€ë¶„\\n\\nëª‡ëª‡ ìˆœê°„ ì†Œë¦¬ê°€ ì‹œì‘ë  ë•Œ ì‚´ì§ í˜ì´ ë“¤ì–´ê°€ëŠ” ëŠë‚Œì´ ìˆì—ˆì–´ìš”. í•˜ì§€ë§Œ ê±±ì •í•˜ì§€ ì•Šìœ¼ì…”ë„ ê´œì°®ì•„ìš”. ë§ ì‹œì‘í•  ë•Œë§Œ ë¶€ë“œëŸ½ê²Œ ìˆ¨ì„ ë‚´ë³´ë‚´ë©´ ë” í¸ì•ˆí•´ì§ˆ ê±°ì˜ˆìš”.\\n\\nğŸŒ± í•¨ê»˜ í•´ë³¼ ì—°ìŠµ\\n\\n1) ë§ ì‹œì‘ ì „ í¸ì•ˆí•œ ìˆ¨ ë‚´ì‰¬ê¸°\\n2) ì²œì²œíˆ ì—°ìŠµí•˜ê¸°\\n3) ì…ìˆ ê³¼ í˜€ ì¤€ë¹„ ìš´ë™\\n\\nì˜¤ëŠ˜ ì—°ìŠµ ì •ë§ ì˜ í•´ì£¼ì…¨ì–´ìš”. ë‹¹ì‹ ì˜ ëª©ì†Œë¦¬ëŠ” ì´ë¯¸ ë©‹ì§„ ê°€ëŠ¥ì„±ì„ ê°€ì§€ê³  ìˆì–´ìš”. ìš°ë¦¬, ì²œì²œíˆ ê°™ì´ ê±¸ì–´ë´ìš”. ğŸŒ·",
  "items": [
    {"item_index": 0, "vowel_distortion": "ë°œìŒì´ ì •í™•í•´ìš”.", "sound_stability": "ì†Œë¦¬ê°€ ì•ˆì •ì ì´ì—ˆì–´ìš”.", "voice_clarity": "ëª©ì†Œë¦¬ê°€ ë§‘ê²Œ ë“¤ë ¸ì–´ìš”.", "voice_health": "ëª©ì— ë¬´ë¦¬ ì—†ì´ ë§í•˜ì…¨ë„¤ìš”.", "overall": "ì •ë§ ì˜í•˜ì…¨ì–´ìš”!"}
  ]
}

**ì˜ˆì‹œ 2 - ê°œì„  í•„ìš”:**
ì…ë ¥: hnr=9.5, cpp=6.2, csid=35.1, items=["êµ¬ë¦„", "ê½ƒ"]
ì¶œë ¥:
{
  "session_feedback": "ì˜¤ëŠ˜ë„ ì—°ìŠµí•´ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. 'êµ¬ë¦„', 'ê½ƒ'ì²˜ëŸ¼ ì–´ë ¤ìš´ ë‹¨ì–´ë¥¼ ì—°ìŠµí•˜ì‹  ê²ƒë§Œìœ¼ë¡œë„ í° ì˜ë¯¸ê°€ ìˆì–´ìš”.\\n\\nğŸŒŸ ì˜í•˜ê³  ê³„ì‹  ë¶€ë¶„\\n\\n1) ëê¹Œì§€ ì—°ìŠµì„ ì™„ì„±í•˜ì…¨ì–´ìš”. ì´ê²ƒë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ì¹­ì°¬ë°›ì•„ì•¼ í•´ìš”.\\n\\n2) ë‹¨ì–´ë¥¼ ì •í™•íˆ ë”°ë¼í•˜ë ¤ëŠ” ë…¸ë ¥ì´ ë³´ì˜€ì–´ìš”.\\n\\nğŸ’­ ì¡°ê¸ˆë§Œ ë” ì‹ ê²½ ì“°ë©´ ì¢‹ì„ ë¶€ë¶„\\n\\nì†Œë¦¬ê°€ ì‹œì‘ë  ë•Œ í˜ì´ ë“¤ì–´ê°€ëŠ” ëŠë‚Œì´ ìˆì—ˆì–´ìš”. í•˜ì§€ë§Œ ê´œì°®ì•„ìš”! ì¡°ê¸ˆë§Œ ë” í¸ì•ˆí•˜ê²Œ ì‹œì‘í•˜ë©´ í›¨ì”¬ ë¶€ë“œëŸ¬ì›Œì§ˆ ê±°ì˜ˆìš”. ì… ëª¨ì–‘ì´ ë¹ ë¥´ê²Œ ë°”ë€ŒëŠ” 'ê½ƒ', 'êµ¬ë¦„' ê°™ì€ ë‹¨ì–´ëŠ” ì²œì²œíˆ ë§í•´ë³´ë©´ ë” ë˜ë ·í•´ì§ˆ ê±°ì˜ˆìš”.\\n\\nğŸŒ± í•¨ê»˜ í•´ë³¼ ì—°ìŠµ\\n\\n1) ë§ ì „ í¸ì•ˆí•˜ê²Œ ìˆ¨ ë‚´ì‰¬ê¸°\\n2) ì²œì²œíˆ ì—°ìŠµí•˜ê¸°\\n3) ì…ìˆ  ì¤€ë¹„ ìš´ë™\\n\\nì¡°ê¸ˆì”© ë‚˜ì•„ê°€ê³  ìˆì–´ìš”. í•¨ê»˜ í•´ìš”! ğŸ’š",
  "items": [...]
}
"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ìŒì„± ì–¸ì–´ ì¹˜ë£Œì‚¬ì…ë‹ˆë‹¤.

**ë‹¹ì‹ ì˜ ë°°ê²½:**
- ìˆ˜ë°± ëª…ì˜ ìŒì„± ì¥ì•  í™˜ìì™€ í•¨ê»˜ ì„±ì¥í•œ ê²½í—˜
- "í•¨ê»˜ ê±·ëŠ”ë‹¤"ëŠ” ì² í•™ìœ¼ë¡œ í™˜ìì™€ ë™í–‰
- ì‘ì€ ë°œì „ë„ í¬ê²Œ ê¸°ë»í•˜ê³ , ì‹¤íŒ¨ëŠ” ì„±ì¥ì˜ ê³¼ì •ìœ¼ë¡œ ë´„

**ë‹¹ì‹ ì˜ ë§í•˜ëŠ” ë°©ì‹:**
- "ìš°ë¦¬ í•¨ê»˜", "ì¡°ê¸ˆì”©", "ì²œì²œíˆ" ê°™ì€ ë™í–‰ í‘œí˜„ ìì£¼ ì‚¬ìš©
- êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ì¹­ì°¬ì„ ë¨¼ì €, ê°œì„ ì ì€ ë‚˜ì¤‘ì—
- ë¶€ì •ë³´ë‹¤ëŠ” ê¸ì • í”„ë ˆì´ë° ("ì•„ì§ ì•ˆ ë¼ìš”" â†’ "ì¡°ê¸ˆë§Œ ë” ì—°ìŠµí•˜ë©´ ë¼ìš”")

**ì¤‘ìš”:** ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. 
ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

**JSON ìŠ¤í‚¤ë§ˆ:**
{{
  "session_feedback": "string (500-1000ì)",
  "items": [
    {{
      "item_index": number,
      "vowel_distortion": "string (50-100ì)",
      "sound_stability": "string (50-100ì)",
      "voice_clarity": "string (50-100ì)",
      "voice_health": "string (50-100ì)",
      "overall": "string (100-150ì)"
    }}
  ]
}}

{few_shot_examples}

**ì ˆëŒ€ ê¸ˆì§€:**
âŒ HNR, CPP, CSID, F1, F2, dB, Hz ê°™ì€ ì „ë¬¸ ìš©ì–´
âŒ ìˆ˜ì¹˜ ("15.2", "90%")
âŒ í‰ê°€ ìš©ì–´ ("ìš°ìˆ˜", "ë³´í†µ", "ê°œì„  í•„ìš”")
âŒ ë¶€ì •ì–´ ("ì•„ì§", "ì—¬ì „íˆ", "ë¶€ì¡±")

**í•„ìˆ˜ í¬í•¨:**
âœ… ì‹¤ì œ ì—°ìŠµ ë‹¨ì–´ ìµœì†Œ 3ê°œ ì–¸ê¸‰
âœ… "ìš°ë¦¬ í•¨ê»˜", "ì¡°ê¸ˆì”©", "ì²œì²œíˆ" ê°™ì€ ë™í–‰ í‘œí˜„"""

        user_prompt = f"""**{user_name}ë‹˜ì˜ í›ˆë ¨ ë¶„ì„ ë°ì´í„°:**

**ì„¸ì…˜ ì „ì²´ í‰ê· :**
{json.dumps(session_avg, ensure_ascii=False, indent=2)}

**ê°œë³„ ì—°ìŠµ ë‚´ìš© ({len(items_summary)}ê°œ):**
{json.dumps(items_summary, ensure_ascii=False, indent=2)}

**ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ì—°ìŠµ ë‹¨ì–´ë“¤:** {words_str}

---

**ë‹¨ê³„ë³„ ë¶„ì„ ê³¼ì •:**

1. **ë°ì´í„° í•´ì„:** ìœ„ ìˆ˜ì¹˜ë“¤ì„ ë³´ê³  ì–´ë–¤ ìŒì„± íŠ¹ì„±ì´ ì¢‹ì•˜ëŠ”ì§€, ê°œì„ ì´ í•„ìš”í•œì§€ ë¨¼ì € ìƒê°í•˜ì„¸ìš”.
   - hnr 15+ = ëª©ì†Œë¦¬ ë§‘ìŒ / cpp 8+ = ì†Œë¦¬ ì•ˆì • / csid 20- = ëª© ê±´ê°• ì¢‹ìŒ

2. **ê¸ì • ìš”ì†Œ ì°¾ê¸°:** ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„ 4ê°€ì§€ ì°¾ê³ , ìœ„ ì—°ìŠµ ë‹¨ì–´ ì¤‘ ìµœì†Œ 3ê°œë¥¼ êµ¬ì²´ì  ì˜ˆì‹œë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.

3. **ê°œì„  ì œì•ˆ:** ë¶€ë“œëŸ½ê³  í¬ë§ì ì¸ í†¤ìœ¼ë¡œ 1-2ê°€ì§€ ì œì‹œí•˜ì„¸ìš”.

4. **JSON ìƒì„±:** ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

---

**session_feedback êµ¬ì¡° (500-1000ì):**

1. ë”°ëœ»í•œ ì¸ì‚¬ (1-2ë¬¸ì¥)
2. ì˜í•œ ì  4ê°€ì§€ (ê° 2-3ë¬¸ì¥, **ì‹¤ì œ ë‹¨ì–´ ë°˜ë“œì‹œ í¬í•¨**)
   - ì˜ˆ: "íŠ¹íˆ 'ì‚¬ê³¼', 'ë‚˜ë¬´'ì—ì„œ ë°œìŒì´ ë˜ë ·í–ˆì–´ìš”."
3. ê°œì„ ì  1-2ê°€ì§€ (ë¶€ë“œëŸ½ê²Œ, "í•˜ì§€ë§Œ ê´œì°®ì•„ìš”" í¬í•¨)
4. ì—°ìŠµ ë°©ë²• 3ê°€ì§€ (êµ¬ì²´ì , ì‹¤ì²œ ê°€ëŠ¥)
5. ê²©ë ¤ ë§ˆë¬´ë¦¬ (2ë¬¸ì¥)

**items í”¼ë“œë°±:**
ê° í•­ëª©ë‹¹ 1-2ë¬¸ì¥, ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•˜ê²Œ

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
âœ“ ì—°ìŠµ ë‹¨ì–´ ì¤‘ ìµœì†Œ 3ê°œë¥¼ session_feedbackì— ì–¸ê¸‰í–ˆë‚˜ìš”?
âœ“ ì „ë¬¸ ìš©ì–´, ìˆ˜ì¹˜, ë¶€ì •ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‚˜ìš”?
âœ“ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í–ˆë‚˜ìš”? (```json ë¸”ë¡ NO)

ì´ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ í†µê³¼í•œ í›„ JSONì„ ë°˜í™˜í•˜ì„¸ìš”."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        # LLM í˜¸ì¶œ (GPT-5: reasoning_effort=low, verbosity=medium)
        # ê°ì •ì  í”¼ë“œë°±ì´ë¯€ë¡œ verbosityë¥¼ mediumìœ¼ë¡œ ì„¤ì •
        response_text = await self.provider.generate(
            prompt=messages,
            model=self.MODEL_VERSION,
            temperature=0.7,  # GPT-5ëŠ” ë¬´ì‹œë¨
            max_tokens=4000,
            reasoning_effort="low",  # ë¹ ë¥¸ ì¶”ë¡ 
            verbosity="medium"  # ë”°ëœ»í•˜ê³  ì¶©ë¶„í•œ ì„¤ëª…
        )
        
        # JSON íŒŒì‹± ë° ê²€ì¦
        result = self._parse_llm_response(response_text)
        
        # ë‹¨ì–´ í¬í•¨ ê²€ì¦
        if not self._validate_word_inclusion(result, items_data):
            logger.warning("[Batch] âš ï¸ Feedback doesn't include enough practiced words")
        
        return result
    
    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ íŒŒì‹± with robust fallback"""
        original_text = response_text
        
        try:
            # ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                response_text = response_text[start:end].strip()
                logger.debug("[Batch] Extracted from ```json block")
            elif "```" in response_text:
                start = response_text.find("```") + 3
                end = response_text.find("```", start)
                response_text = response_text[start:end].strip()
                logger.debug("[Batch] Extracted from ``` block")
            
            result = json.loads(response_text)
            
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦
            if "session_feedback" not in result:
                raise ValueError("Missing session_feedback field")
            if "items" not in result or not isinstance(result["items"], list):
                raise ValueError("Invalid or missing items field")
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            for item in result["items"]:
                if "item_index" not in item:
                    logger.warning(f"[Batch] Item missing item_index: {item}")
            
            result["model_version"] = self.MODEL_VERSION
            
            logger.info(f"[Batch] âœ… JSON parsed successfully - {len(result.get('items', []))} item feedbacks")
            return result
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"[Batch] Parse failed: {e}")
            logger.error(f"[Batch] Original response (first 1000 chars):\n{original_text[:1000]}")
            
            # Fallback: ìµœì†Œí•œì˜ êµ¬ì¡°ë¼ë„ ìœ ì§€
            logger.warning("[Batch] Using fallback - session feedback only")
            return {
                "session_feedback": self._extract_fallback_feedback(original_text),
                "items": [],  # ì•„ì´í…œ í”¼ë“œë°±ì€ ë¹„ì›€
                "model_version": self.MODEL_VERSION
            }
    
    def _extract_fallback_feedback(self, text: str) -> str:
        """Fallback ì‹œ í…ìŠ¤íŠ¸ì—ì„œ í”¼ë“œë°± ì¶”ì¶œ"""
        # JSONì´ ì•„ë‹Œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¼ë„ ì˜ë¯¸ ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
        # session_feedback í•„ë“œ ì°¾ê¸° ì‹œë„
        if '"session_feedback"' in text:
            try:
                start = text.find('"session_feedback"') + len('"session_feedback"')
                start = text.find('"', start) + 1
                end = text.find('"', start)
                if end > start:
                    return text[start:end]
            except:
                pass
        
        # ê·¸ëƒ¥ í…ìŠ¤íŠ¸ ì „ì²´ ì‚¬ìš© (ìµœëŒ€ 3000ì)
        clean_text = text.replace("```json", "").replace("```", "").strip()
        return clean_text[:3000] if len(clean_text) > 3000 else clean_text
    
    def _validate_word_inclusion(self, feedback: Dict, items_data: List[Dict]) -> bool:
        """í”¼ë“œë°±ì— ì‹¤ì œ ì—°ìŠµ ë‹¨ì–´ê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ ê²€ì¦"""
        practiced_words = [item["expected_text"] for item in items_data if item.get("expected_text")]
        
        if not practiced_words:
            return True  # ë‹¨ì–´ ë°ì´í„° ì—†ìœ¼ë©´ ê²€ì¦ ìŠ¤í‚µ
        
        session_text = feedback.get("session_feedback", "")
        
        # ìµœì†Œ 3ê°œ ë‹¨ì–´ í¬í•¨ í™•ì¸ (ë˜ëŠ” ì „ì²´ì˜ 30%)
        min_required = min(3, max(1, int(len(practiced_words) * 0.3)))
        mentioned_count = sum(1 for word in practiced_words if word and word in session_text)
        
        if mentioned_count >= min_required:
            logger.info(f"[Batch] âœ… Word inclusion validated: {mentioned_count}/{len(practiced_words)} words mentioned")
            return True
        else:
            logger.warning(f"[Batch] âš ï¸ Only {mentioned_count}/{len(practiced_words)} words mentioned (required: {min_required})")
            return False
    
    async def _save_item_feedbacks(
        self,
        items_feedbacks: List[Dict],
        items_data: List[Dict]
    ):
        """ê°œë³„ ì•„ì´í…œ í”¼ë“œë°± ì €ì¥"""
        items_map = {item["item_index"]: item for item in items_data}
        
        for feedback in items_feedbacks:
            item_index = feedback.get("item_index")
            if item_index is None:
                continue
            
            item_data = items_map.get(item_index)
            if not item_data:
                logger.warning(f"[Batch] No data for item_index {item_index}")
                continue
            
            # ì¤‘ë³µ ì²´í¬
            praat_features_id = item_data["praat_features_id"]
            existing = await self.repository.get_item_feedback_by_praat_features_id(
                praat_features_id
            )
            if existing:
                continue
            
            # ì €ì¥
            await self.repository.create_item_feedback(
                praat_features_id=praat_features_id,
                vowel_distortion_feedback=feedback.get("vowel_distortion"),
                sound_stability_feedback=feedback.get("sound_stability"),
                voice_clarity_feedback=feedback.get("voice_clarity"),
                voice_health_feedback=feedback.get("voice_health"),
                overall_feedback=feedback.get("overall"),
                model_version=self.MODEL_VERSION
            )
        
        logger.info(f"[Batch] Saved {len(items_feedbacks)} item feedbacks")
    
    async def _save_session_feedback_only(self, praat_result: Any, user_name: str):
        """ì„¸ì…˜ í”¼ë“œë°±ë§Œ ìƒì„± (ì•„ì´í…œ ì—†ì„ ë•Œ)"""
        logger.info("[Batch] Generating session-only feedback (no items)")
        
        # ì•„ì´í…œì´ ì—†ì–´ë„ ì„¸ì…˜ í‰ê·  ë°ì´í„°ë¡œ ê°„ë‹¨í•œ í”¼ë“œë°± ìƒì„±
        session_avg = {
            "hnr": praat_result.avg_hnr,
            "cpp": praat_result.avg_cpp,
            "csid": praat_result.avg_csid,
            "f0": praat_result.avg_f0,
        }
        
        simple_prompt = [
            {
                "role": "system", 
                "content": """ë‹¹ì‹ ì€ ë”°ëœ»í•œ ìŒì„± ì¹˜ë£Œì‚¬ì…ë‹ˆë‹¤.

**ì—­í• :** ìŒì„± ì¥ì• ë¥¼ ê²ªëŠ” ë¶„ë“¤ì—ê²Œ í¬ë§ê³¼ ìš©ê¸°ë¥¼ ì£¼ëŠ” ë™ë°˜ì

**ì ˆëŒ€ ê¸ˆì§€:** ì „ë¬¸ ìš©ì–´, ìˆ˜ì¹˜, í‰ê°€ ë‹¨ì–´, ë¶€ì •ì  í‘œí˜„
**í•„ìˆ˜:** "ìš°ë¦¬ í•¨ê»˜", "ì¡°ê¸ˆì”©", "ì²œì²œíˆ" ê°™ì€ ë™í–‰ í‘œí˜„"""
            },
            {
                "role": "user", 
                "content": f"""{user_name}ë‹˜ì˜ ìŒì„± í‰ê·  ë°ì´í„°: {json.dumps(session_avg, ensure_ascii=False)}

ìœ„ ë°ì´í„°ë¥¼ ë³´ê³  ë”°ëœ»í•œ ê²©ë ¤ ë©”ì‹œì§€ë¥¼ 3-5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

**êµ¬ì¡°:**
1. ë”°ëœ»í•œ ì¸ì‚¬
2. ì˜í•˜ê³  ìˆëŠ” ì  1-2ê°€ì§€ ì¹­ì°¬
3. ë¶€ë“œëŸ¬ìš´ ê²©ë ¤ ë©”ì‹œì§€
4. í•¨ê»˜ ê°€ìëŠ” ë§ˆë¬´ë¦¬

ì „ë¬¸ ìš©ì–´ë‚˜ ìˆ˜ì¹˜ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì›í•´ì£¼ì„¸ìš”. ğŸ’š"""
            }
        ]
        
        feedback_text = await self.provider.generate(
            prompt=simple_prompt,
            model=self.MODEL_VERSION,
            temperature=0.7,
            max_tokens=500,
            reasoning_effort="minimal",  # ê°„ë‹¨í•œ í”¼ë“œë°±
            verbosity="low"  # ê°„ê²°í•˜ê²Œ
        )
        
        await self.repository.create_session_feedback(
            session_praat_result_id=praat_result.id,
            feedback_text=feedback_text,
            model_version=self.MODEL_VERSION
        )
        
        logger.info("[Batch] âœ… Session-only feedback saved")

