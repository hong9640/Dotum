"""
AI Service - Wav2Lip ë¦½ì‹±í¬ ì²˜ë¦¬
"""

import os
import sys
import subprocess
import tempfile
import time
import torch
import shutil
from typing import Optional
from api.utils.gcs_client import gcs_client
from api.core.config import settings
from api.core.logger import logger, log_step, log_success, log_error

# Wav2Lip inference ëª¨ë“ˆì€ _load_wav2lip_modelì—ì„œ ë™ì ìœ¼ë¡œ import
WAV2LIP_AVAILABLE = False


class AIService:
    """AI ëª¨ë¸ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.gcs_client = gcs_client
        self._optimal_batch_size = self._detect_optimal_batch_size()
        self._wav2lip_model = None  # ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ìƒì£¼
        self._model_device = None
        self._load_wav2lip_model()  # ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ
    
    async def process_lip_video_pipeline(
        self,
        user_video_gs: str,
        gen_audio_gs: str,
        output_video_gs: str,
        target_fps: int = 18
    ) -> dict:
        """
        ë¦½ì‹±í¬ ì˜ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            user_video_gs: ì‚¬ìš©ì ì—…ë¡œë“œ ì˜ìƒ GCS ê²½ë¡œ
            gen_audio_gs: ìƒì„±ëœ ì˜¤ë””ì˜¤ GCS ê²½ë¡œ
            output_video_gs: ê²°ê³¼ ì˜ìƒ ì—…ë¡œë“œ ê²½ë¡œ
            
        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
        """
        start_time = time.time()
        temp_files = []
        step_times = {}
        
        try:
            # 1. GCSì—ì„œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            step_start = time.time()
            log_step("Downloading video from GCS")
            video_local_path = await self._download_file_from_gcs(
                user_video_gs, 
                f"video_{int(time.time())}.mp4"
            )
            if not video_local_path:
                raise ValueError("Failed to download video from GCS")
            temp_files.append(video_local_path)
            step_times["1_download_video"] = time.time() - step_start
            log_success(f"Video downloaded ({step_times['1_download_video']:.2f}s)", path=video_local_path)
            
            # 2. GCSì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            step_start = time.time()
            log_step("Downloading audio from GCS")
            audio_local_path = await self._download_file_from_gcs(
                gen_audio_gs, 
                f"audio_{int(time.time())}.wav"
            )
            if not audio_local_path:
                raise ValueError("Failed to download audio from GCS")
            temp_files.append(audio_local_path)
            step_times["2_download_audio"] = time.time() - step_start
            log_success(f"Audio downloaded ({step_times['2_download_audio']:.2f}s)", path=audio_local_path)
            
            # 3. Wav2Lip ë¦½ì‹±í¬
            step_start = time.time()
            log_step("Running Wav2Lip inference and uploading to GCS")
            result_video_path = await self._run_wav2lip_inference(
                face_video_path=video_local_path,
                audio_path=audio_local_path,
                output_gs_path=output_video_gs,
                use_gpu=True,
                target_fps=target_fps
            )
            if not result_video_path:
                raise ValueError("Failed to run Wav2Lip inference or upload to GCS")
            step_times["3_wav2lip"] = time.time() - step_start
            log_success(f"Wav2Lip completed ({step_times['3_wav2lip']:.2f}s)", path=result_video_path)
            
            process_time_ms = (time.time() - start_time) * 1000
            
            # ì„±ëŠ¥ ë¶„ì„ ë¡œê·¸
            logger.info("=" * 60)
            logger.info("Performance Analysis:")
            logger.info(f"  1. Download Video:    {step_times['1_download_video']:>7.2f}s ({step_times['1_download_video']/process_time_ms*100000:.1f}%)")
            logger.info(f"  2. Download Audio:    {step_times['2_download_audio']:>7.2f}s ({step_times['2_download_audio']/process_time_ms*100000:.1f}%)")
            logger.info(f"  3. Wav2Lip:           {step_times['3_wav2lip']:>7.2f}s ({step_times['3_wav2lip']/process_time_ms*100000:.1f}%)")
            logger.info(f"  Total:                {process_time_ms/1000:>7.2f}s (100.0%)")
            logger.info("=" * 60)
            
            return {
                "success": True,
                "result_video_gs": output_video_gs,
                "process_time_ms": process_time_ms
            }
            
        except Exception as e:
            log_error(f"Pipeline failed: {e}")
            raise
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleaned_count = 0
            for temp_file in temp_files:
                if temp_file and os.path.exists(temp_file):
                    try:
                        os.unlink(temp_file)
                        cleaned_count += 1
                    except Exception as e:
                        logger.warning(f"Failed to clean up {temp_file}: {e}")
            if cleaned_count > 0:
                logger.info(f"Cleaned up {cleaned_count} temporary files")
    
    def _load_wav2lip_model(self):
        """Wav2Lip ëª¨ë¸ì„ GPU ë©”ëª¨ë¦¬ì— ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)"""
        global WAV2LIP_AVAILABLE
        
        # ê²½ë¡œ ì„¤ì •
        wav2lip_path = settings.LOCAL_WAV2LIP_PATH
        if wav2lip_path and wav2lip_path not in sys.path:
            sys.path.insert(0, wav2lip_path)
        
        # ë™ì  import ì‹œë„
        try:
            from wav2lip_inference import run_wav2lip_inference
            from models import Wav2Lip
            WAV2LIP_AVAILABLE = True
            self._run_wav2lip_inference_func = run_wav2lip_inference
            logger.info("Wav2Lip inference module imported successfully")
        except ImportError as e:
            logger.warning(f"Could not import Wav2Lip inference module: {e}, will use subprocess method")
            WAV2LIP_AVAILABLE = False
            self._run_wav2lip_inference_func = None
            return
        
        if not torch.cuda.is_available():
            logger.warning("CUDA not available, model will be loaded on CPU")
            self._model_device = 'cpu'
        else:
            self._model_device = 'cuda'
        
        try:
            model_path = os.path.join(settings.LOCAL_WAV2LIP_PATH, "checkpoints", "wav2lip_gan.pth")
            if not os.path.exists(model_path):
                logger.warning(f"Wav2Lip model not found: {model_path}, will use subprocess method")
                return
            
            logger.info("Loading Wav2Lip model into GPU memory (one-time initialization)...")
            
            # ëª¨ë¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=self._model_device)
            s = checkpoint["state_dict"]
            new_s = {}
            for k, v in s.items():
                new_s[k.replace('module.', '')] = v
            
            model = Wav2Lip()
            model.load_state_dict(new_s)
            model = model.to(self._model_device)
            
            # FP16 ë³€í™˜
            if self._model_device == 'cuda':
                try:
                    model = model.half()
                    logger.info("Model converted to FP16 (half precision)")
                except Exception as e:
                    logger.warning(f"Could not convert to FP16: {e}, using FP32")
            
            # torch.compile
            try:
                if hasattr(torch, 'compile') and self._model_device == 'cuda':
                    model = torch.compile(model, mode='reduce-overhead')
                    logger.info("Model compiled with torch.compile")
            except Exception as e:
                logger.debug(f"torch.compile not available: {e}")
            
            model.eval()
            self._wav2lip_model = model
            
            logger.info("âœ… Wav2Lip model loaded and ready in GPU memory (will be reused for all requests)")
            
        except Exception as e:
            logger.error(f"Failed to load Wav2Lip model: {e}, will use subprocess method")
            self._wav2lip_model = None
    
    def _detect_optimal_batch_size(self) -> int:
        """GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ ê°ì§€ (L4 GPU ìµœì í™”)"""
        if not torch.cuda.is_available():
            logger.warning("CUDA not available, using CPU batch size: 8")
            return 8
        
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        gpu_name = torch.cuda.get_device_properties(0).name
        
        logger.info(f"GPU detected: {gpu_name}, Memory: {gpu_memory_gb:.2f}GB")
        
        # L4 GPU (24GB) + STT ëª¨ë¸ ê³ ë ¤: STTê°€ ê°€ë³ë‹¤ê³  í–ˆìœ¼ë¯€ë¡œ Wav2Lipì— ë” ë§ì€ ë©”ëª¨ë¦¬ í• ë‹¹ ê°€ëŠ¥
        # nvidia-smiì—ì„œ 3.4GBë§Œ ì‚¬ìš© ì¤‘ì´ë¯€ë¡œ ë” í° ë°°ì¹˜ ê°€ëŠ¥
        if gpu_memory_gb >= 40:
            batch_size = 48  # A100 ë“±: ë” í° ë°°ì¹˜
        elif gpu_memory_gb >= 22:  # L4 GPU (ì•½ 22-24GB ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥)
            batch_size = 48  # L4: ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìœ¼ë¯€ë¡œ 48ë¡œ ì¦ê°€ (32 â†’ 48)
        elif gpu_memory_gb >= 15:  # T4 GPU (15.75GB)
            batch_size = 24  # T4: ì¦ê°€ (16 â†’ 24)
        elif gpu_memory_gb >= 12:
            batch_size = 16  # 12GB GPU
        else:
            batch_size = 8  # 8GB ì´í•˜
        
        logger.info(f"Optimal batch size determined: {batch_size} (GPU: {gpu_name}, {gpu_memory_gb:.2f}GB)")
        return batch_size
    
    async def _download_file_from_gcs(self, gs_path: str, filename: str) -> Optional[str]:
        """GCSì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            local_path = f"/tmp/{filename}"
            
            if not self.gcs_client.download_file(gs_path, local_path):
                logger.error(f"Failed to download file: {gs_path}")
                return None
            
            logger.info(f"File downloaded to tmp: {local_path}")
            return local_path
            
        except Exception as e:
            logger.error(f"Failed to download file from GCS: {e}")
            return None
    
    async def _run_wav2lip_inference(
        self,
        face_video_path: str,
        audio_path: str,
        output_gs_path: str,
        use_gpu: bool = True,
        target_fps: int = 18
    ) -> Optional[str]:
        """Wav2Lip ë¦½ì‹±í¬ (ëª¨ë¸ ì¬ì‚¬ìš© - GPU ë©”ëª¨ë¦¬ ìƒì£¼)"""
        try:
            with tempfile.TemporaryDirectory() as tmp_dir:
                # ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
                audio_local = os.path.join(tmp_dir, "audio.wav")
                shutil.copy2(audio_path, audio_local)
                
                # ì˜ìƒ íŒŒì¼ ì²˜ë¦¬
                face_local = os.path.join(tmp_dir, "face_input.mp4")
                shutil.copy2(face_video_path, face_local)
                
                # ì›ë³¸ ì˜ìƒ í•´ìƒë„ ì¶”ì¶œ (FFprobe)
                original_resolution = await self._get_video_resolution(face_local)
                logger.info(f"Original video resolution: {original_resolution}")
                
                output_temp = os.path.join(tmp_dir, "lipsynced_temp.mp4")  # ì„ì‹œ ì¶œë ¥
                output_local = os.path.join(tmp_dir, "lipsynced.mp4")  # ìµœì¢… ì¶œë ¥
                
                # GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
                device = "cuda" if torch.cuda.is_available() and use_gpu else "cpu"
                logger.info(f"Running Wav2Lip on {device.upper()}")
                
                # GPU íŒŒë¼ë¯¸í„° ì„¤ì • (L4 GPU ìµœì í™”)
                if device == "cuda":
                    batch_size = self._optimal_batch_size
                    face_det_batch = min(self._optimal_batch_size // 2, 24)
                    logger.info(f"L4 GPU detected: Using batch_size={batch_size}, face_det_batch={face_det_batch}")
                else:
                    batch_size = 8
                    face_det_batch = 4
                
                # ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì§ì ‘ ì‚¬ìš© (ë¹ ë¦„!)
                if self._wav2lip_model is not None and WAV2LIP_AVAILABLE and hasattr(self, '_run_wav2lip_inference_func'):
                    logger.info("ğŸš€ Using pre-loaded model from GPU memory (fast path - no model reload!)")
                    
                    # temp ë””ë ‰í† ë¦¬ ìƒì„±
                    temp_dir = os.path.join(settings.LOCAL_WAV2LIP_PATH, "temp")
                    os.makedirs(temp_dir, exist_ok=True)
                    
                    # ì§ì ‘ inference í•¨ìˆ˜ í˜¸ì¶œ (ëª¨ë¸ ì¬ì‚¬ìš©)
                    self._run_wav2lip_inference_func(
                        model=self._wav2lip_model,
                        face_video_path=face_local,
                        audio_path=audio_local,
                        output_path=output_temp,
                        device=device,
                        wav2lip_batch_size=batch_size,
                        face_det_batch_size=face_det_batch,
                        face_detector='scrfd',
                        pads=[0, 15, 0, 0],
                        resize_factor=1,
                        box=[-1, -1, -1, -1],
                        static=False,
                        nosmooth=False
                    )
                    
                    if not os.path.exists(output_temp):
                        logger.error(f"Wav2Lip output file not found: {output_temp}")
                        return None
                else:
                    # Fallback: subprocess ë°©ì‹ (ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ)
                    logger.warning("Using subprocess method (model not pre-loaded)")
                    model_local = os.path.join(settings.LOCAL_WAV2LIP_PATH, "checkpoints", "wav2lip_gan.pth")
                    if not os.path.exists(model_local):
                        logger.error(f"Wav2Lip model not found: {model_local}")
                        return None
                    
                    wav2lip_dir = settings.LOCAL_WAV2LIP_PATH
                    inference_path = os.path.join(wav2lip_dir, "inference.py")
                    python_exec = sys.executable if hasattr(sys, 'executable') else "python3"
                    
                    cmd = [
                        python_exec, inference_path,
                        "--checkpoint_path", model_local,
                        "--face", face_local,
                        "--audio", audio_local,
                        "--outfile", output_temp,
                        "--pads", "0", "15", "0", "0",
                        "--wav2lip_batch_size", str(batch_size),
                        "--face_det_batch_size", str(face_det_batch),
                        "--resize_factor", "1",
                        "--box", "-1", "-1", "-1", "-1",
                        "--face_detector", "scrfd",
                    ]
                    
                    logger.info(f"Running Wav2Lip inference (subprocess): {' '.join(cmd)}")
                    result = subprocess.run(cmd, capture_output=True, text=True, cwd=wav2lip_dir)
                    
                    if result.returncode != 0:
                        logger.error(f"Wav2Lip inference failed: {result.stderr}")
                        return None
                    
                    if not os.path.exists(output_temp):
                        logger.error(f"Wav2Lip output file not found: {output_temp}")
                        return None
                
                # í›„ì²˜ë¦¬: ì›ë³¸ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ê³ í’ˆì§ˆ ìŠ¤ì¼€ì¼ë§) + FPS ì¡°ì •
                logger.info(f"Resizing output to original resolution: {original_resolution} @ {target_fps}fps with HIGH QUALITY (GPU accel: {torch.cuda.is_available()})")
                resize_success = await self._resize_video_to_resolution(
                    input_path=output_temp,
                    output_path=output_local,
                    resolution=original_resolution,
                    target_fps=target_fps,
                    original_video_path=face_local  # ì›ë³¸ ì˜ìƒ ê²½ë¡œ ì „ë‹¬ (ë¹„íŠ¸ë ˆì´íŠ¸ ì¶”ì¶œìš©)
                )
                
                if not resize_success or not os.path.exists(output_local):
                    logger.error("Failed to resize video to original resolution")
                    return None
                
                # GCSì— ì—…ë¡œë“œ
                logger.info(f"Uploading to GCS: {output_local} -> {output_gs_path}")
                if not self.gcs_client.upload_file(output_local, output_gs_path):
                    logger.error("Failed to upload Wav2Lip output to GCS")
                    return None
                    
                logger.info(f"Wav2Lip inference completed: {output_gs_path}")
                return output_gs_path
                    
        except Exception as e:
            logger.error(f"Failed to run Wav2Lip inference: {e}")
            return None
    
    async def _get_video_resolution(self, video_path: str) -> str:
        """
        FFprobeë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì˜ í•´ìƒë„ë¥¼ ì¶”ì¶œ
        
        Returns:
            str: "widthxheight" í˜•ì‹ (ì˜ˆ: "1280x720")
        """
        try:
            cmd = [
                "ffprobe",
                "-v", "error",
                "-select_streams", "v:0",
                "-show_entries", "stream=width,height",
                "-of", "csv=s=x:p=0",
                video_path
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            resolution = result.stdout.strip()
            logger.info(f"Detected video resolution: {resolution}")
            return resolution
            
        except subprocess.CalledProcessError as e:
            logger.error(f"FFprobe failed: {e.stderr}")
            return "1280x720"  # ê¸°ë³¸ê°’
        except Exception as e:
            logger.error(f"Failed to get video resolution: {e}")
            return "1280x720"  # ê¸°ë³¸ê°’
    
    async def _get_video_bitrate(self, video_path: str) -> str:
        """
        FFprobeë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì˜ ë¹„íŠ¸ë ˆì´íŠ¸ë¥¼ ì¶”ì¶œ
        
        Returns:
            str: ë¹„íŠ¸ë ˆì´íŠ¸ (ì˜ˆ: "5000k") ë˜ëŠ” None
        """
        try:
            cmd = [
                "ffprobe",
                "-v", "error",
                "-select_streams", "v:0",
                "-show_entries", "stream=bit_rate",
                "-of", "default=noprint_wrappers=1:nokey=1",
                video_path
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            bitrate = result.stdout.strip()
            if bitrate and bitrate.isdigit():
                # bpsë¥¼ kbpsë¡œ ë³€í™˜
                bitrate_kbps = int(int(bitrate) / 1000)
                logger.info(f"Detected video bitrate: {bitrate_kbps}k")
                return f"{bitrate_kbps}k"
            
            logger.warning("Could not detect bitrate, will use CRF mode")
            return None
            
        except subprocess.CalledProcessError as e:
            logger.error(f"FFprobe bitrate detection failed: {e.stderr}")
            return None
        except Exception as e:
            logger.error(f"Failed to get video bitrate: {e}")
            return None
    
    async def _resize_video_to_resolution(
        self,
        input_path: str,
        output_path: str,
        resolution: str,
        target_fps: int = 18,
        original_video_path: str = None
    ) -> bool:
        """
        FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì„ íŠ¹ì • í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
        
        í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸:
        - CPU: ìŠ¤ì¼€ì¼ë§ (lanczos, ê³ í’ˆì§ˆ) + FPS ì¡°ì ˆ
        - GPU: ì¸ì½”ë”© (h264_nvenc, ë¹ ë¥¸ ì†ë„)
        - ì˜¤ë””ì˜¤: ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)
        
        Args:
            input_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            resolution: ëª©í‘œ í•´ìƒë„ "widthxheight" (ì˜ˆ: "1280x720")
            target_fps: ëª©í‘œ í”„ë ˆì„ë¥  (ê¸°ë³¸ê°’: 18fps)
            original_video_path: ì›ë³¸ ì˜ìƒ ê²½ë¡œ (ë¹„íŠ¸ë ˆì´íŠ¸ ì¶”ì¶œìš©)
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì›ë³¸ ë¹„íŠ¸ë ˆì´íŠ¸ ì¶”ì¶œ (ì›ë³¸ í™”ì§ˆ ìœ ì§€)
            original_bitrate = None
            if original_video_path:
                original_bitrate = await self._get_video_bitrate(original_video_path)
            
            # GPU ì¸ì½”ë”© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            gpu_encoding_available = torch.cuda.is_available()
            
            # í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸: CPU ìŠ¤ì¼€ì¼ë§ + GPU ì¸ì½”ë”© (ì†ë„ ìµœì í™”)
            # ìŠ¤ì¼€ì¼ë§ í•„í„°: fast_bilinear (lanczosë³´ë‹¤ ë¹ ë¥´ì§€ë§Œ ì—¬ì „íˆ ì¢‹ì€ í’ˆì§ˆ)
            cmd = [
                "ffmpeg",
                "-y",
                "-i", input_path,
                "-vf", f"scale={resolution}:flags=fast_bilinear,fps={target_fps}",  # ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§
                "-c:v", "h264_nvenc" if gpu_encoding_available else "libx264",  # GPU ì¸ì½”ë”© (ê°€ëŠ¥ ì‹œ)
                "-preset", "fast",  # ë¹ ë¥¸ ì¸ì½”ë”© (medium -> fast)
            ]
            
            # ë¹„íŠ¸ë ˆì´íŠ¸ ë˜ëŠ” CRF ì„¤ì •
            if original_bitrate:
                logger.info(f"Using original bitrate: {original_bitrate}")
                cmd.extend([
                    "-b:v", original_bitrate,
                    "-maxrate", original_bitrate,
                    "-bufsize", f"{int(original_bitrate.replace('k', '')) * 2}k",
                ])
            else:
                if gpu_encoding_available:
                    # NVENC: QP 21 (19ë³´ë‹¤ ì•½ê°„ ë¹ ë¥´ì§€ë§Œ ì—¬ì „íˆ ê³ í’ˆì§ˆ)
                    cmd.extend(["-rc", "constqp", "-qp", "21"])
                    logger.info("Using NVENC QP 21 (fast high quality)")
                else:
                    # CPU: CRF 18 (15ë³´ë‹¤ ë¹ ë¥´ì§€ë§Œ ì—¬ì „íˆ ì¢‹ì€ í’ˆì§ˆ) + ë©€í‹°ìŠ¤ë ˆë”©
                    cmd.extend(["-crf", "18", "-threads", "0"])
                    logger.info("Using CRF 18 with multithreading (fast high quality)")
            
            # ê³µí†µ ì˜µì…˜
            cmd.extend([
                "-pix_fmt", "yuv420p",
                "-c:a", "copy",  # ì˜¤ë””ì˜¤ ë³µì‚¬
                output_path
            ])
            
            logger.info(f"Hybrid pipeline (CPU scale + {'GPU' if gpu_encoding_available else 'CPU'} encode): {' '.join(cmd)}")
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            logger.info(f"Video resized successfully to {resolution} @ {target_fps}fps")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"FFmpeg resize failed: {e.stderr}")
            return False
        except Exception as e:
            logger.error(f"Failed to resize video: {e}")
            return False


# AI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
ai_service = AIService()

