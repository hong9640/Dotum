# ğŸ¤ ë°œì„± ì—°ìŠµ ì œì¶œ í˜•ì‹

## ğŸ“¦ ë°±ì—”ë“œ API ìš”êµ¬ì‚¬í•­

### ì—”ë“œí¬ì¸íŠ¸
```
POST /train/training-sessions/{session_id}/vocal/{item_index}/submit
```

### ìš”ì²­ í˜•ì‹ (FormData)
```typescript
{
  audio_file: File,      // âœ… í•„ìˆ˜ - WAV í˜•ì‹
  graph_image: File,     // âœ… í•„ìˆ˜ - PNG í˜•ì‹
  graph_video?: File     // â­• ì„ íƒ - MP4 í˜•ì‹ (í˜„ì¬ ë¯¸êµ¬í˜„)
}
```

---

## ğŸ¯ í˜„ì¬ êµ¬í˜„ ë°©ì‹

### 1. ì˜¤ë””ì˜¤ ë…¹ìŒ (âœ… ì™„ë£Œ)
**ê¸°ìˆ :** `MediaRecorder API` + `useAudioRecorder` hook

```typescript
// ë…¹ìŒ ì‹œì‘
await navigator.mediaDevices.getUserMedia({ audio: true })
const mediaRecorder = new MediaRecorder(stream)

// ë…¹ìŒ ì™„ë£Œ â†’ audioBlob (WAV)
const audioFile = new File([audioBlob], 'mpt_1.wav', { type: 'audio/wav' })
```

**ê²°ê³¼ë¬¼:** `Blob` â†’ WAV íŒŒì¼

---

### 2. ê·¸ë˜í”„ ì‹œê°í™” (âœ… ì™„ë£Œ)
**ê¸°ìˆ :** `MeydaGraph` ì»´í¬ë„ŒíŠ¸ (Canvas ê¸°ë°˜)

**íŠ¹ì§•:**
- ì‹¤ì‹œê°„ RMS â†’ dBFS ë³€í™˜
- -60 ~ 0 dB ë²”ìœ„ í‘œì‹œ
- EMA ìŠ¤ë¬´ë”© ì ìš©
- ì¢Œâ†’ìš° ìŠ¤í¬ë¡¤ ë¼ì¸ ê·¸ë˜í”„

```typescript
// ì‹¤ì‹œê°„ ê·¸ë¦¬ê¸°
analyser.getFloatTimeDomainData(timeDomainData)
const rms = calculateRMS(timeDomainData)
const dBFS = 20 * Math.log10(rms)
ctx.lineTo(x, dbToY(dBFS))
```

---

### 3. ê·¸ë˜í”„ ì´ë¯¸ì§€ ìº¡ì²˜ (âœ… ì™„ë£Œ)
**ê¸°ìˆ :** `Canvas.toBlob()` API

```typescript
// MeydaGraphì—ì„œ ì´ë¯¸ì§€ ìº¡ì²˜
const captureImage = async (): Promise<Blob | null> => {
  return new Promise((resolve) => {
    canvas.toBlob((blob) => {
      resolve(blob);
    }, 'image/png');
  });
}

// ì‚¬ìš© ì˜ˆì‹œ
const graphImageBlob = await graphRef.current?.captureImage();
const graphImageFile = new File([graphImageBlob], 'mpt_1_graph.png', { 
  type: 'image/png' 
});
```

**ê²°ê³¼ë¬¼:** `Blob` â†’ PNG ì´ë¯¸ì§€

---

### 4. ë°±ì—”ë“œ ì „ì†¡ (âœ… ì™„ë£Œ)

```typescript
// src/api/voice-training/index.ts
export const submitVocalItem = async ({
  sessionId,
  itemIndex,
  audioFile,      // WAV íŒŒì¼
  graphImage,     // PNG íŒŒì¼
  // graphVideo,  // ë¯¸êµ¬í˜„ (ì„ íƒì‚¬í•­)
  onUploadProgress
}: SubmitVocalItemRequest) => {
  const formData = new FormData();
  formData.append('audio_file', audioFile);
  formData.append('graph_image', graphImage);
  
  const response = await apiClient.post(
    `/train/training-sessions/${sessionId}/vocal/${itemIndex}/submit`,
    formData,
    {
      headers: { 'Content-Type': 'multipart/form-data' },
      onUploadProgress
    }
  );
  
  return response.data;
};
```

---

## ğŸ“Š ë°ì´í„° í”Œë¡œìš°

```
ì‚¬ìš©ì ë…¹ìŒ ì‹œì‘
    â†“
[1] MediaRecorder â†’ audioBlob (WAV)
    â†“
[2] MeydaGraph ì‹¤ì‹œê°„ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (Canvas)
    â†“
ì‚¬ìš©ì ë…¹ìŒ ì¢…ë£Œ â†’ "ì œì¶œí•˜ê¸°" ë²„íŠ¼ í´ë¦­
    â†“
[3] canvas.toBlob() â†’ graphImageBlob (PNG)
    â†“
[4] FormData ìƒì„±
    - audio_file: audioBlob
    - graph_image: graphImageBlob
    â†“
[5] POST /train/training-sessions/{id}/vocal/{idx}/submit
    â†“
[6] ë°±ì—”ë“œ ì‘ë‹µ
    - session (ì—…ë°ì´íŠ¸ëœ ì„¸ì…˜ ì •ë³´)
    - is_completed í™•ì¸
    â†“
[7] is_completed === true â†’ ë‹¤ìŒ ì‹œë„/ì—°ìŠµ í™œì„±í™”
```

---

## ğŸ¬ ê·¸ë˜í”„ ì˜ìƒ (ë¯¸êµ¬í˜„, ì„ íƒì‚¬í•­)

### êµ¬í˜„ ì‹œ í•„ìš” ê¸°ìˆ 
```typescript
// MediaRecorderë¡œ Canvas ìŠ¤íŠ¸ë¦¼ ë…¹í™”
const canvasStream = canvas.captureStream(30); // 30 FPS
const videoRecorder = new MediaRecorder(canvasStream, {
  mimeType: 'video/webm;codecs=vp9',
  videoBitsPerSecond: 2500000
});

// ë…¹í™” ì™„ë£Œ â†’ Blob
const videoBlob = new Blob(chunks, { type: 'video/webm' });

// WebM â†’ MP4 ë³€í™˜ í•„ìš” (ffmpeg.wasm)
const mp4Blob = await convertToMP4(videoBlob);
```

**ë¯¸êµ¬í˜„ ì´ìœ :**
- ë°±ì—”ë“œì—ì„œ ì„ íƒì‚¬í•­ìœ¼ë¡œ ëª…ì‹œ
- ì´ë¯¸ì§€ë§Œìœ¼ë¡œë„ ì¶©ë¶„í•œ ì •ë³´ ì œê³µ
- ì¶”ê°€ êµ¬í˜„ ì‹œê°„ ë° ë³µì¡ë„ ê³ ë ¤

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] ì˜¤ë””ì˜¤ ë…¹ìŒ (WAV)
- [x] ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì‹œê°í™” (dBFS)
- [x] ê·¸ë˜í”„ ì´ë¯¸ì§€ ìº¡ì²˜ (PNG)
- [x] FormData êµ¬ì„±
- [x] API ì „ì†¡
- [x] is_completed í™•ì¸
- [ ] ê·¸ë˜í”„ ì˜ìƒ ë…¹í™” (ì„ íƒì‚¬í•­, ë¯¸êµ¬í˜„)

---

## ğŸš€ ì‚¬ìš© ì˜ˆì‹œ

```typescript
// src/pages/voice-training/mpt.tsx
const handleSubmit = async (audioBlob: Blob, graphImageBlob: Blob) => {
  const itemIndex = attempt - 1; // MPT: 0, 1, 2
  
  const result = await submitVocalItem({
    sessionId,
    itemIndex,
    audioFile: new File([audioBlob], `mpt_${attempt}.wav`, { 
      type: 'audio/wav' 
    }),
    graphImage: new File([graphImageBlob], `mpt_${attempt}_graph.png`, { 
      type: 'image/png' 
    }),
  });
  
  // ì™„ë£Œ ì—¬ë¶€ í™•ì¸
  const currentItem = result.session.training_items?.find(
    item => item.item_index === itemIndex
  );
  
  if (currentItem?.is_completed) {
    setIsCompleted(true); // ë‹¤ìŒ ë‹¨ê³„ í™œì„±í™”
  }
};
```

---

## ğŸ“ íŒŒì¼ëª… ê·œì¹™

| ì—°ìŠµ íƒ€ì… | ì˜¤ë””ì˜¤ íŒŒì¼ | ê·¸ë˜í”„ ì´ë¯¸ì§€ |
|-----------|-------------|---------------|
| MPT | `mpt_1.wav` | `mpt_1_graph.png` |
| Crescendo | `crescendo_1.wav` | `crescendo_1_graph.png` |
| Decrescendo | `decrescendo_1.wav` | `decrescendo_1_graph.png` |
| Loud-Soft | `loud_soft_1.wav` | `loud_soft_1_graph.png` |
| Soft-Loud | `soft_loud_1.wav` | `soft_loud_1_graph.png` |

(ìˆ«ìëŠ” attempt: 1, 2, 3)

